{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6VfTqhMUWbN"
   },
   "source": [
    "Objective\n",
    "About: This was originally a competition hosted\n",
    "on kaggle.com consisting of a classification\n",
    "problem in computer vision.\n",
    "1. Problem statement: Given the dataset\n",
    "consisting of driver images in car and\n",
    "corresponding labels for 10 nos. categories (e.g.\n",
    "safe driving, texting, talking etc.), your task is to\n",
    "build a classification model to predict the\n",
    "category for that image.\n",
    "2. Dataset link: After creating an account on\n",
    "Kaggle, go to this competition page\n",
    "(https://www.kaggle.com/c/state-farmdistracted-driver-detection) and Join Competition.\n",
    "After joining the competition, you can either\n",
    "download the data on your local machine or you\n",
    "can use Kaggle kernel (like jupyter notebook) to\n",
    "build and train your model (recommended as it\n",
    "provides you with GPU computing to train your\n",
    "neural network and no need to download the\n",
    "dataset locally).\n",
    "Notes\n",
    "1. You can resubmit till your code is not evaluated\n",
    "by TA.\n",
    "2. This is a concluded competition and therefore,\n",
    "you need to keep aside a part of training data as\n",
    "test data to evaluate your model.\n",
    "3. If you want, you may use Transfer Learning\n",
    "(building your model on top of pretrained open\n",
    "sourced model) in this problem.\n",
    "Comments : Your code must have proper\n",
    "comments for better understanding.\n",
    "Score : Score will be given by the TA based on\n",
    "your submission.\n",
    "Submission : You have to upload only. ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NWWJvBeiSUy-"
   },
   "outputs": [],
   "source": [
    "# First step is to mount the drive\n",
    "\n",
    "#import necessary libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from subprocess import call\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.utils import to_categorical,Sequence\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xt7LBI2aTS3W"
   },
   "outputs": [],
   "source": [
    "PATH = \"/content/drive/MyDrive/Colab Notebooks/Coding_ninja_computer_vision/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ViQm02BhTe98",
    "outputId": "1eaeabe9-7aaf-44e3-c22d-bb9451469a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content/drive/MyDrive/Colab Notebooks/Coding_ninja_computer_vision\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(PATH)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNDhjIpAThsi",
    "outputId": "1144ed6d-a1ea-4502-a0e8-1f622ec9a2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'c4', 'c3', 'c2', 'c1', 'c0']\n"
     ]
    }
   ],
   "source": [
    "# Dictionary: key - folder name, value - Category\n",
    "class_map = {'c0': 'safe driving',\n",
    "            'c1': 'texting - right',\n",
    "            'c2': 'talking on the phone - right',\n",
    "            'c3': 'texting - left',\n",
    "            'c4': 'talking on the phone - left'\n",
    "            }\n",
    "train_path = 'data/train'   # Train data path\n",
    "val_path = 'data/validation'       # Validation data path\n",
    "classes = os.listdir(train_path)\n",
    "#del classes[0]\n",
    "#classes.remove('.DS_Store')\n",
    "# List of directories in train path\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFKnQph8TpOg",
    "outputId": "4d96cae7-a3cf-4435-bcf5-982bed8b1e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int32), array([24, 24, 24, 24, 24]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.) # 0 - 1\n",
    "\n",
    "# This is a generator that will read pictures found in subfolers of 'train', and generates\n",
    "# batches of augmented image data on the fly\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(224,224))\n",
    "\n",
    "np.unique(train_generator.classes, return_counts=True)# no class imbalance\n",
    "# Please note that in the presence of class imbalance, class_weights parameter helps long way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFvGnqxnTqvg",
    "outputId": "3cc40181-6836-436f-8043-2b5abfac5632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# This is the augmentation configuration we will use for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "val_generator = val_datagen.flow_from_directory(directory=val_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False,\n",
    "                                                    target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k0ljLbFTfX3F"
   },
   "outputs": [],
   "source": [
    "# Sequential is a container in keras which is used to stack layers in order\n",
    "# First layer should include the input data shape. This is mandatory.\n",
    "# Padding valid implies no padding\n",
    "# Padding SAME implies enough padding so that output has the same dimensions as input\n",
    "# Initial layers identify fewer basic features like edges while later layers identify a lot of more abstract features.\n",
    "# Therefore, no. of filters increase as we go deeper into the network.\n",
    "# Batchormalization is standard in convolution layers. Improves the convergence time.\n",
    "# Activation is applied after the Batch normalization\n",
    "# Dropout could be used for regularization in the fully-connected part of the network\n",
    "\n",
    "def image_classifier(nb_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(224, 224, 3), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(5, 5), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return(model)\n",
    "\n",
    "\n",
    "# Cross Entropy is the standard loss function for classification tasks.\n",
    "# Adam is the most popular optimizer. Convergence is quick. Could be unstable sometimes.\n",
    "# Learning Rate Schedulers could be used for stabilizing training process\n",
    "# The 'metrics' mentioned will be computed during run time. So that we can monitor the progress.\n",
    "\n",
    "model = image_classifier(nb_classes=5)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX7l_zCSf6gI",
    "outputId": "94ca11ee-71da-4d0d-c686-604265d86991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 220, 220, 32)      2432      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 220, 220, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 220, 220, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 110, 110, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 106, 106, 64)      51264     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 106, 106, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 106, 106, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 53, 53, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 49, 49, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 49, 49, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 49, 49, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 24, 24, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 73728)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 73728)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              75498496  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75763141 (289.01 MB)\n",
      "Trainable params: 75762693 (289.01 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re8sWZ9if9Pk",
    "outputId": "1bdb9a70-76aa-47e3-de2e-8aa816ea10ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.2044 - accuracy: 0.9250 - val_loss: 2.5318 - val_accuracy: 0.3778\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.1772 - accuracy: 0.9667 - val_loss: 2.5181 - val_accuracy: 0.3778\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 0.1645 - accuracy: 0.9750 - val_loss: 2.5156 - val_accuracy: 0.3778\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.2549 - accuracy: 0.9083 - val_loss: 2.5415 - val_accuracy: 0.3556\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.1916 - accuracy: 0.9583 - val_loss: 2.5753 - val_accuracy: 0.3556\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 0.2378 - accuracy: 0.9167 - val_loss: 2.7225 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 487ms/step - loss: 0.1685 - accuracy: 0.9500 - val_loss: 2.8145 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 0.2183 - accuracy: 0.9250 - val_loss: 2.8264 - val_accuracy: 0.3556\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.2096 - accuracy: 0.9583 - val_loss: 2.6483 - val_accuracy: 0.3556\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.1914 - accuracy: 0.9583 - val_loss: 2.4993 - val_accuracy: 0.3556\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 625ms/step - loss: 0.1533 - accuracy: 0.9583 - val_loss: 2.3910 - val_accuracy: 0.3556\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 692ms/step - loss: 0.1335 - accuracy: 0.9917 - val_loss: 2.3940 - val_accuracy: 0.3778\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.1544 - accuracy: 0.9583 - val_loss: 2.4674 - val_accuracy: 0.3778\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 619ms/step - loss: 0.1494 - accuracy: 0.9500 - val_loss: 2.5802 - val_accuracy: 0.3778\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.1795 - accuracy: 0.9667 - val_loss: 2.6206 - val_accuracy: 0.3778\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 2.4552 - val_accuracy: 0.3778\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.1501 - accuracy: 0.9833 - val_loss: 2.2949 - val_accuracy: 0.3778\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.1442 - accuracy: 0.9500 - val_loss: 2.2592 - val_accuracy: 0.3778\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 516ms/step - loss: 0.2267 - accuracy: 0.9333 - val_loss: 2.3028 - val_accuracy: 0.3778\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.1930 - accuracy: 0.9250 - val_loss: 2.4297 - val_accuracy: 0.3778\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.1280 - accuracy: 0.9667 - val_loss: 2.5088 - val_accuracy: 0.3778\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 0.1546 - accuracy: 0.9750 - val_loss: 2.5061 - val_accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 768ms/step - loss: 0.1788 - accuracy: 0.9667 - val_loss: 2.5362 - val_accuracy: 0.3778\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 615ms/step - loss: 0.1755 - accuracy: 0.9500 - val_loss: 2.5074 - val_accuracy: 0.3778\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 0.1274 - accuracy: 0.9833 - val_loss: 2.4436 - val_accuracy: 0.3778\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.1302 - accuracy: 0.9833 - val_loss: 2.3581 - val_accuracy: 0.3778\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.1511 - accuracy: 0.9500 - val_loss: 2.2016 - val_accuracy: 0.3778\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 0.1571 - accuracy: 0.9500 - val_loss: 2.1209 - val_accuracy: 0.3778\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.1797 - accuracy: 0.9167 - val_loss: 2.2412 - val_accuracy: 0.4000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 522ms/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 2.4274 - val_accuracy: 0.4000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.1570 - accuracy: 0.9583 - val_loss: 2.5115 - val_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 680ms/step - loss: 0.1139 - accuracy: 0.9833 - val_loss: 2.3899 - val_accuracy: 0.4000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 922ms/step - loss: 0.1409 - accuracy: 0.9583 - val_loss: 2.1893 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 0.1204 - accuracy: 0.9750 - val_loss: 2.0195 - val_accuracy: 0.4000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 718ms/step - loss: 0.1584 - accuracy: 0.9417 - val_loss: 1.9257 - val_accuracy: 0.4000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 775ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 1.8512 - val_accuracy: 0.4000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 1.8537 - val_accuracy: 0.4222\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0860 - accuracy: 0.9833 - val_loss: 1.8847 - val_accuracy: 0.4667\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.0952 - accuracy: 0.9833 - val_loss: 1.9785 - val_accuracy: 0.4889\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 2.1051 - val_accuracy: 0.4889\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 2.1524 - val_accuracy: 0.4889\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 0.0757 - accuracy: 0.9917 - val_loss: 2.1333 - val_accuracy: 0.4889\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 0.0926 - accuracy: 0.9833 - val_loss: 2.1110 - val_accuracy: 0.4889\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 0.1118 - accuracy: 0.9583 - val_loss: 2.0784 - val_accuracy: 0.4667\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 1.9626 - val_accuracy: 0.4222\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 0.0779 - accuracy: 0.9750 - val_loss: 1.8857 - val_accuracy: 0.4889\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 718ms/step - loss: 0.1435 - accuracy: 0.9417 - val_loss: 1.8640 - val_accuracy: 0.4444\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 0.0658 - accuracy: 0.9917 - val_loss: 1.8717 - val_accuracy: 0.4667\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 0.1199 - accuracy: 0.9833 - val_loss: 1.8819 - val_accuracy: 0.4889\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 446ms/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 1.8569 - val_accuracy: 0.4889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7da7515b7f70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit returns the history of loss and metrics for train and validation datasets.\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                           validation_data=val_generator,\n",
    "                           epochs=50) #steps_per_epoch=120/64.0,validation_steps=45/64.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1URK8kZgw37"
   },
   "source": [
    "# Training is coming correct not the validating part, lets do some other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "72jZ2x3rg6a7"
   },
   "outputs": [],
   "source": [
    "# Import ImageDataGenerator for image preprocessing/augmentation\n",
    "# This basically creates multiple copies of train images by jittering(adding noise).\n",
    "# This includes rotating, zooming in, flipping, shifting, etc.\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest') # 'nearest' is kind of algorithm to fill pixel values while transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1k7Y2OPhM56",
    "outputId": "bdc0ffdc-e42b-4f96-a7b9-a24b2c40a9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import ImageDataGenerator for image preprocessing/augmentation\n",
    "# This basically creates multiple copies of train images by jittering(adding noise).\n",
    "# This includes rotating, zooming in, flipping, shifting, etc.\n",
    "# This is the augmentation configuration we will use for training\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                                    rotation_range=20,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    zoom_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzMgcr6xhYDX",
    "outputId": "b488c1ba-3883-4315-c98e-39d3cd8c6266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "val_generator = train_datagen.flow_from_directory(directory=val_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False,\n",
    "                                                    target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QLvJtyiohalX"
   },
   "outputs": [],
   "source": [
    "# Cross Entropy is the standard loss function for classification tasks.\n",
    "# Adam is the most popular optimizer. Convergence is quick. Could be unstable sometimes.\n",
    "# Learning Rate Schedulers could be used for stabilizing training process\n",
    "# The 'metrics' mentioned will be computed during run time. So that we can monitor the progress.\n",
    "\n",
    "model = image_classifier(nb_classes=5)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iC-B7aSPhcyS",
    "outputId": "4d2a7736-2c34-4359-b3c8-b089c62abdb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 255.2942 - accuracy: 0.2250 - val_loss: 61.8437 - val_accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 134.8690 - accuracy: 0.2167 - val_loss: 38.9812 - val_accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 49.2167 - accuracy: 0.2167 - val_loss: 33.7465 - val_accuracy: 0.2000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 39.6485 - accuracy: 0.2083 - val_loss: 36.7033 - val_accuracy: 0.2889\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 42.5673 - accuracy: 0.2333 - val_loss: 43.0599 - val_accuracy: 0.2222\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 37.4730 - accuracy: 0.2500 - val_loss: 50.3079 - val_accuracy: 0.1778\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 4s 3s/step - loss: 28.0989 - accuracy: 0.1500 - val_loss: 40.7996 - val_accuracy: 0.1778\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 23.6755 - accuracy: 0.1833 - val_loss: 33.0831 - val_accuracy: 0.1778\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 13.4295 - accuracy: 0.2083 - val_loss: 16.6723 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 5s 4s/step - loss: 9.4675 - accuracy: 0.2333 - val_loss: 16.9957 - val_accuracy: 0.2000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 11.8704 - accuracy: 0.2250 - val_loss: 24.3101 - val_accuracy: 0.2000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 8.7279 - accuracy: 0.2333 - val_loss: 23.9589 - val_accuracy: 0.2444\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 7.2745 - accuracy: 0.2000 - val_loss: 17.9428 - val_accuracy: 0.2000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 5.9422 - accuracy: 0.1583 - val_loss: 13.6728 - val_accuracy: 0.2222\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 5.3823 - accuracy: 0.1833 - val_loss: 10.0374 - val_accuracy: 0.2000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 3.3902 - accuracy: 0.2500 - val_loss: 7.8169 - val_accuracy: 0.2889\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 2.2416 - accuracy: 0.2750 - val_loss: 5.3455 - val_accuracy: 0.2667\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 4s 3s/step - loss: 1.8534 - accuracy: 0.2250 - val_loss: 3.8372 - val_accuracy: 0.2889\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6854 - accuracy: 0.2333 - val_loss: 3.6863 - val_accuracy: 0.2444\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6615 - accuracy: 0.1917 - val_loss: 3.2115 - val_accuracy: 0.1778\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5777 - accuracy: 0.2167 - val_loss: 2.9821 - val_accuracy: 0.2222\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5953 - accuracy: 0.2167 - val_loss: 2.2670 - val_accuracy: 0.2889\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.6040 - accuracy: 0.2250 - val_loss: 2.1786 - val_accuracy: 0.1778\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5902 - accuracy: 0.1667 - val_loss: 1.9845 - val_accuracy: 0.3111\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6060 - accuracy: 0.2333 - val_loss: 2.0023 - val_accuracy: 0.2222\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5991 - accuracy: 0.1833 - val_loss: 1.8326 - val_accuracy: 0.2889\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.6093 - accuracy: 0.1917 - val_loss: 1.7350 - val_accuracy: 0.2667\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5665 - accuracy: 0.2333 - val_loss: 1.9472 - val_accuracy: 0.1333\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5852 - accuracy: 0.2000 - val_loss: 1.7071 - val_accuracy: 0.2667\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6011 - accuracy: 0.2417 - val_loss: 1.9236 - val_accuracy: 0.2222\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5455 - accuracy: 0.2750 - val_loss: 1.7757 - val_accuracy: 0.2889\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6418 - accuracy: 0.2250 - val_loss: 1.7728 - val_accuracy: 0.3556\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6165 - accuracy: 0.2167 - val_loss: 1.5951 - val_accuracy: 0.2889\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5807 - accuracy: 0.2583 - val_loss: 1.5499 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5959 - accuracy: 0.1917 - val_loss: 1.6460 - val_accuracy: 0.2444\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6081 - accuracy: 0.2250 - val_loss: 1.6069 - val_accuracy: 0.2889\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5788 - accuracy: 0.2250 - val_loss: 1.5007 - val_accuracy: 0.3111\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 4s 3s/step - loss: 1.5721 - accuracy: 0.2583 - val_loss: 1.5893 - val_accuracy: 0.3111\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5843 - accuracy: 0.2250 - val_loss: 1.6661 - val_accuracy: 0.2889\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5813 - accuracy: 0.2667 - val_loss: 1.5595 - val_accuracy: 0.2222\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5751 - accuracy: 0.2750 - val_loss: 1.6062 - val_accuracy: 0.2000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.6089 - accuracy: 0.2667 - val_loss: 1.5376 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5817 - accuracy: 0.2417 - val_loss: 1.5413 - val_accuracy: 0.3556\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5892 - accuracy: 0.2333 - val_loss: 1.5526 - val_accuracy: 0.2444\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.5784 - accuracy: 0.2667 - val_loss: 1.5862 - val_accuracy: 0.2222\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 4s 3s/step - loss: 1.5732 - accuracy: 0.2583 - val_loss: 1.5645 - val_accuracy: 0.2889\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5518 - accuracy: 0.3000 - val_loss: 1.5506 - val_accuracy: 0.3111\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5982 - accuracy: 0.2167 - val_loss: 1.5428 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.5530 - accuracy: 0.2833 - val_loss: 1.5843 - val_accuracy: 0.2889\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.5632 - accuracy: 0.2583 - val_loss: 1.5179 - val_accuracy: 0.3778\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e40218c6addc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m hist0 = model.fit_generator(train_generator, \n\u001b[1;32m      4\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                            epochs=50).history()\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# model.fit returns the history of loss and metrics for train and validation datasets.\n",
    "\n",
    "hist0 = model.fit_generator(train_generator,\n",
    "                           validation_data=val_generator,\n",
    "                           epochs=50).history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_l-pYM9iEeb"
   },
   "source": [
    "# Though images are augmented, results are not good\n",
    "# Lets go for tranfer learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aVOGGlVsiHVz"
   },
   "outputs": [],
   "source": [
    "# Get Inception architecture from keras.applications\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "def inception_tl(nb_classes, freez_wts):\n",
    "\n",
    "    trained_model = InceptionV3(include_top=False,weights='imagenet')\n",
    "    x = trained_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    pred_inception= Dense(nb_classes,activation='softmax')(x)\n",
    "    model = Model(inputs=trained_model.input,outputs=pred_inception)\n",
    "\n",
    "    for layer in trained_model.layers:\n",
    "        layer.trainable=(1-freez_wts)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEXioyDKinw2",
    "outputId": "8413cd7c-a62c-43aa-bf6e-8a60575d8cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, None, None, 32)       864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, None, None, 32)       96        ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, None, None, 32)       0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, None, None, 32)       9216      ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, None, None, 32)       96        ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, None, None, 32)       0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, None, None, 64)       18432     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, None, None, 64)       192       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, None, None, 64)       0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, None, None, 64)       0         ['activation_11[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, None, None, 80)       5120      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, None, None, 80)       240       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, None, None, 80)       0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, None, None, 192)      138240    ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, None, None, 192)      576       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, None, None, 192)      0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, None, None, 192)      0         ['activation_13[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, None, None, 64)       12288     ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, None, None, 64)       192       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, None, None, 64)       0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, None, None, 48)       9216      ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, None, None, 96)       55296     ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, None, None, 48)       144       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, None, None, 96)       288       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, None, None, 48)       0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, None, None, 96)       0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, None, None, 192)      0         ['max_pooling2d_10[0][0]']    \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, None, None, 64)       12288     ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, None, None, 64)       76800     ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, None, None, 96)       82944     ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, None, None, 32)       6144      ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, None, None, 64)       192       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, None, None, 64)       192       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, None, None, 96)       288       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, None, None, 32)       96        ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, None, None, 64)       0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, None, None, 64)       0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, None, None, 96)       0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, None, None, 32)       0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, None, None, 256)      0         ['activation_14[0][0]',       \n",
      "                                                                     'activation_16[0][0]',       \n",
      "                                                                     'activation_19[0][0]',       \n",
      "                                                                     'activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, None, None, 64)       16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, None, None, 64)       192       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, None, None, 64)       0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, None, None, 48)       12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, None, None, 96)       55296     ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, None, None, 48)       144       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, None, None, 96)       288       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, None, None, 48)       0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, None, None, 96)       0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, None, None, 256)      0         ['mixed0[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, None, None, 64)       16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, None, None, 64)       76800     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, None, None, 96)       82944     ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, None, None, 64)       16384     ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, None, None, 64)       192       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, None, None, 64)       192       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, None, None, 96)       288       ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, None, None, 64)       192       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, None, None, 64)       0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, None, None, 64)       0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, None, None, 96)       0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, None, None, 64)       0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, None, None, 288)      0         ['activation_21[0][0]',       \n",
      "                                                                     'activation_23[0][0]',       \n",
      "                                                                     'activation_26[0][0]',       \n",
      "                                                                     'activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, None, None, 64)       18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, None, None, 64)       192       ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, None, None, 64)       0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, None, None, 48)       13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, None, None, 96)       55296     ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, None, None, 48)       144       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, None, None, 96)       288       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, None, None, 48)       0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, None, None, 96)       0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (Avera  (None, None, None, 288)      0         ['mixed1[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, None, None, 64)       18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, None, None, 64)       76800     ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, None, None, 96)       82944     ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, None, None, 64)       18432     ['average_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, None, None, 64)       192       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, None, None, 64)       192       ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, None, None, 96)       288       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, None, None, 64)       192       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, None, None, 64)       0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, None, None, 64)       0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, None, None, 96)       0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, None, None, 64)       0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, None, None, 288)      0         ['activation_28[0][0]',       \n",
      "                                                                     'activation_30[0][0]',       \n",
      "                                                                     'activation_33[0][0]',       \n",
      "                                                                     'activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, None, None, 64)       18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, None, None, 64)       192       ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, None, None, 64)       0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, None, None, 96)       55296     ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, None, None, 96)       288       ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, None, None, 96)       0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, None, None, 384)      995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, None, None, 96)       82944     ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, None, None, 384)      1152      ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, None, None, 96)       288       ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, None, None, 384)      0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, None, None, 96)       0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, None, None, 288)      0         ['mixed2[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, None, None, 768)      0         ['activation_35[0][0]',       \n",
      "                                                                     'activation_38[0][0]',       \n",
      "                                                                     'max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, None, None, 128)      98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, None, None, 128)      384       ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, None, None, 128)      0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, None, None, 128)      114688    ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, None, None, 128)      384       ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, None, None, 128)      0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, None, None, 128)      98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, None, None, 128)      114688    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, None, None, 128)      384       ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, None, None, 128)      384       ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, None, None, 128)      0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, None, None, 128)      0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, None, None, 128)      114688    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, None, None, 128)      114688    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, None, None, 128)      384       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, None, None, 128)      384       ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, None, None, 128)      0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, None, None, 128)      0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (Avera  (None, None, None, 768)      0         ['mixed3[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, None, None, 192)      147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, None, None, 192)      172032    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, None, None, 192)      172032    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, None, None, 192)      147456    ['average_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, None, None, 192)      576       ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, None, None, 192)      576       ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, None, None, 192)      576       ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, None, None, 192)      576       ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, None, None, 192)      0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, None, None, 192)      0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, None, None, 192)      0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, None, None, 192)      0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, None, None, 768)      0         ['activation_39[0][0]',       \n",
      "                                                                     'activation_42[0][0]',       \n",
      "                                                                     'activation_47[0][0]',       \n",
      "                                                                     'activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, None, None, 160)      122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, None, None, 160)      480       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, None, None, 160)      0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, None, None, 160)      179200    ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (None, None, None, 160)      480       ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, None, None, 160)      0         ['batch_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, None, None, 160)      122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, None, None, 160)      179200    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, None, None, 160)      480       ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (None, None, None, 160)      480       ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, None, None, 160)      0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, None, None, 160)      0         ['batch_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, None, None, 160)      179200    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, None, None, 160)      179200    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, None, None, 160)      480       ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (None, None, None, 160)      480       ['conv2d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, None, None, 160)      0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, None, None, 160)      0         ['batch_normalization_56[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (Avera  (None, None, None, 768)      0         ['mixed4[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, None, None, 192)      147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, None, None, 192)      215040    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, None, None, 192)      215040    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, None, None, 192)      147456    ['average_pooling2d_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, None, None, 192)      576       ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, None, None, 192)      576       ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (None, None, None, 192)      576       ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (None, None, None, 192)      576       ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, None, None, 192)      0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, None, None, 192)      0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, None, None, 192)      0         ['batch_normalization_57[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, None, None, 192)      0         ['batch_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, None, None, 768)      0         ['activation_49[0][0]',       \n",
      "                                                                     'activation_52[0][0]',       \n",
      "                                                                     'activation_57[0][0]',       \n",
      "                                                                     'activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, None, None, 160)      122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (None, None, None, 160)      480       ['conv2d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, None, None, 160)      0         ['batch_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, None, None, 160)      179200    ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, None, None, 160)      480       ['conv2d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, None, None, 160)      0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, None, None, 160)      122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, None, None, 160)      179200    ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (None, None, None, 160)      480       ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, None, None, 160)      480       ['conv2d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, None, None, 160)      0         ['batch_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, None, None, 160)      0         ['batch_normalization_65[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, None, None, 160)      179200    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, None, None, 160)      179200    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (None, None, None, 160)      480       ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, None, None, 160)      480       ['conv2d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, None, None, 160)      0         ['batch_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, None, None, 160)      0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (Avera  (None, None, None, 768)      0         ['mixed5[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, None, None, 192)      147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, None, None, 192)      215040    ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, None, None, 192)      215040    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, None, None, 192)      147456    ['average_pooling2d_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (None, None, None, 192)      576       ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (None, None, None, 192)      576       ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, None, None, 192)      576       ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, None, None, 192)      576       ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, None, None, 192)      0         ['batch_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, None, None, 192)      0         ['batch_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, None, None, 192)      0         ['batch_normalization_67[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, None, None, 192)      0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, None, None, 768)      0         ['activation_59[0][0]',       \n",
      "                                                                     'activation_62[0][0]',       \n",
      "                                                                     'activation_67[0][0]',       \n",
      "                                                                     'activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_73 (Ba  (None, None, None, 192)      576       ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, None, None, 192)      0         ['batch_normalization_73[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, None, None, 192)      258048    ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_74 (Ba  (None, None, None, 192)      576       ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, None, None, 192)      0         ['batch_normalization_74[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, None, None, 192)      258048    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (None, None, None, 192)      576       ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_75 (Ba  (None, None, None, 192)      576       ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, None, None, 192)      0         ['batch_normalization_70[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, None, None, 192)      0         ['batch_normalization_75[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, None, None, 192)      258048    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (None, None, None, 192)      258048    ['activation_75[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (None, None, None, 192)      576       ['conv2d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_76 (Ba  (None, None, None, 192)      576       ['conv2d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, None, None, 192)      0         ['batch_normalization_71[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, None, None, 192)      0         ['batch_normalization_76[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (Avera  (None, None, None, 768)      0         ['mixed6[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, None, None, 192)      258048    ['activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (None, None, None, 192)      258048    ['activation_76[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (None, None, None, 192)      147456    ['average_pooling2d_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, None, None, 192)      576       ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_72 (Ba  (None, None, None, 192)      576       ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_77 (Ba  (None, None, None, 192)      576       ['conv2d_77[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_78 (Ba  (None, None, None, 192)      576       ['conv2d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, None, None, 192)      0         ['batch_normalization_69[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, None, None, 192)      0         ['batch_normalization_72[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, None, None, 192)      0         ['batch_normalization_77[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, None, None, 192)      0         ['batch_normalization_78[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, None, None, 768)      0         ['activation_69[0][0]',       \n",
      "                                                                     'activation_72[0][0]',       \n",
      "                                                                     'activation_77[0][0]',       \n",
      "                                                                     'activation_78[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (None, None, None, 192)      147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (None, None, None, 192)      576       ['conv2d_81[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, None, None, 192)      0         ['batch_normalization_81[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (None, None, None, 192)      258048    ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (None, None, None, 192)      576       ['conv2d_82[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, None, None, 192)      0         ['batch_normalization_82[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (None, None, None, 192)      147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, None, None, 192)      258048    ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_79 (Ba  (None, None, None, 192)      576       ['conv2d_79[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (None, None, None, 192)      576       ['conv2d_83[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, None, None, 192)      0         ['batch_normalization_79[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, None, None, 192)      0         ['batch_normalization_83[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (None, None, None, 320)      552960    ['activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (None, None, None, 192)      331776    ['activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_80 (Ba  (None, None, None, 320)      960       ['conv2d_80[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (None, None, None, 192)      576       ['conv2d_84[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, None, None, 320)      0         ['batch_normalization_80[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, None, None, 192)      0         ['batch_normalization_84[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooli  (None, None, None, 768)      0         ['mixed7[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, None, None, 1280)     0         ['activation_80[0][0]',       \n",
      "                                                                     'activation_84[0][0]',       \n",
      "                                                                     'max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, None, None, 448)      573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, None, None, 448)      1344      ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, None, None, 448)      0         ['batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (None, None, None, 384)      491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (None, None, None, 384)      1548288   ['activation_89[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, None, None, 384)      1152      ['conv2d_86[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, None, None, 384)      1152      ['conv2d_90[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, None, None, 384)      0         ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (None, None, None, 384)      0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, None, None, 384)      442368    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, None, None, 384)      442368    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, None, None, 384)      442368    ['activation_90[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, None, None, 384)      442368    ['activation_90[0][0]']       \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (Avera  (None, None, None, 1280)     0         ['mixed8[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, None, None, 320)      409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, None, None, 384)      1152      ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, None, None, 384)      1152      ['conv2d_88[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, None, None, 384)      1152      ['conv2d_91[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, None, None, 384)      1152      ['conv2d_92[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (None, None, None, 192)      245760    ['average_pooling2d_7[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (None, None, None, 320)      960       ['conv2d_85[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, None, None, 384)      0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, None, None, 384)      0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_91 (Activation)  (None, None, None, 384)      0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_92 (Activation)  (None, None, None, 384)      0         ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, None, None, 192)      576       ['conv2d_93[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, None, None, 320)      0         ['batch_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, None, None, 768)      0         ['activation_87[0][0]',       \n",
      "                                                                     'activation_88[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, None, 768)      0         ['activation_91[0][0]',       \n",
      "                                                                     'activation_92[0][0]']       \n",
      "                                                                                                  \n",
      " activation_93 (Activation)  (None, None, None, 192)      0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, None, None, 2048)     0         ['activation_85[0][0]',       \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate[0][0]',         \n",
      "                                                                     'activation_93[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, None, None, 448)      917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, None, None, 448)      1344      ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_98 (Activation)  (None, None, None, 448)      0         ['batch_normalization_98[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)          (None, None, None, 384)      786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, None, None, 384)      1548288   ['activation_98[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, None, None, 384)      1152      ['conv2d_95[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, None, None, 384)      1152      ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, None, None, 384)      0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_99 (Activation)  (None, None, None, 384)      0         ['batch_normalization_99[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (None, None, None, 384)      442368    ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (None, None, None, 384)      442368    ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, None, None, 384)      442368    ['activation_99[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, None, None, 384)      442368    ['activation_99[0][0]']       \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (Avera  (None, None, None, 2048)     0         ['mixed9[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)          (None, None, None, 320)      655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, None, None, 384)      1152      ['conv2d_96[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, None, None, 384)      1152      ['conv2d_97[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, None, None, 384)      1152      ['conv2d_100[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, None, None, 384)      1152      ['conv2d_101[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, None, None, 192)      393216    ['average_pooling2d_8[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, None, None, 320)      960       ['conv2d_94[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, None, None, 384)      0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, None, None, 384)      0         ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_100 (Activation  (None, None, None, 384)      0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_101 (Activation  (None, None, None, 384)      0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, None, None, 192)      576       ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_94 (Activation)  (None, None, None, 320)      0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, None, None, 768)      0         ['activation_96[0][0]',       \n",
      "                                                                     'activation_97[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, None, None, 768)      0         ['activation_100[0][0]',      \n",
      " )                                                                   'activation_101[0][0]']      \n",
      "                                                                                                  \n",
      " activation_102 (Activation  (None, None, None, 192)      0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, None, None, 2048)     0         ['activation_94[0][0]',       \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_1[0][0]',       \n",
      "                                                                     'activation_102[0][0]']      \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['mixed10[0][0]']             \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 5)                    10245     ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21813029 (83.21 MB)\n",
      "Trainable params: 21778597 (83.08 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = inception_tl(nb_classes=5, freez_wts=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yarhm4zfiqNs",
    "outputId": "6acc0a7a-56e9-475d-9920-25ff07469a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7600 - accuracy: 0.1917 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3.0 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 68s 18s/step - loss: 1.7600 - accuracy: 0.1917 - val_loss: 5.6651 - val_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 2s 854ms/step - loss: 1.3401 - accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 2s 855ms/step - loss: 0.7475 - accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3627 - accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 3s 868ms/step - loss: 0.3752 - accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2044 - accuracy: 0.9333\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 2s 900ms/step - loss: 0.2085 - accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2689 - accuracy: 0.9500\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1160 - accuracy: 0.9500\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0533 - accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 2s 856ms/step - loss: 0.0335 - accuracy: 0.9917\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 2s 900ms/step - loss: 0.0928 - accuracy: 0.9750\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 2s 855ms/step - loss: 0.1114 - accuracy: 0.9750\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0412 - accuracy: 0.9833\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1349 - accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 2s 880ms/step - loss: 0.0437 - accuracy: 0.9833\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 2s 865ms/step - loss: 0.0635 - accuracy: 0.9833\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1090 - accuracy: 0.9833\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0609 - accuracy: 0.9750\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0671 - accuracy: 0.9750\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0603 - accuracy: 0.9833\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0453 - accuracy: 0.9833\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0592 - accuracy: 0.9833\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0720 - accuracy: 0.9750\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 2s 861ms/step - loss: 0.0143 - accuracy: 0.9917\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0110 - accuracy: 0.9917\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0751 - accuracy: 0.9917\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0127 - accuracy: 0.9917\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0101 - accuracy: 0.9917\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 2s 855ms/step - loss: 0.0330 - accuracy: 0.9833\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 2s 856ms/step - loss: 0.0187 - accuracy: 0.9917\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0162 - accuracy: 0.9917\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0604 - accuracy: 0.9917\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 2s 860ms/step - loss: 0.0204 - accuracy: 0.9833\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 3s 2s/step - loss: 7.7793e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 2s 863ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-de625ffb4459>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m hist1 = model.fit_generator(train_generator, \n\u001b[0m\u001b[1;32m      3\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            steps_per_epoch=120/60,validation_steps=45/15).history\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "hist1 = model.fit_generator(train_generator,\n",
    "                           validation_data=val_generator,\n",
    "                           epochs=100,\n",
    "                           steps_per_epoch=120/60,validation_steps=45/15).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3oFercG7iypu"
   },
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(generator=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "K1UYQ0S4i5kS",
    "outputId": "f69064ea-60e0-4fcf-ae86-12ebc4b59cd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f1fc134d-4988-405b-a4e7-55751fa7dd27\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0/img_1005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0/img_104.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0/img_139.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0/img_208.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0/img_231.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c0/img_262.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c0/img_292.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c0/img_34.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c0/img_981.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c1/img_1045.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1fc134d-4988-405b-a4e7-55751fa7dd27')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f1fc134d-4988-405b-a4e7-55751fa7dd27 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f1fc134d-4988-405b-a4e7-55751fa7dd27');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-68616946-4eb1-44bd-b4bb-be1b22b4f838\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68616946-4eb1-44bd-b4bb-be1b22b4f838')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-68616946-4eb1-44bd-b4bb-be1b22b4f838 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             image  prediction\n",
       "0  c0/img_1005.jpg           0\n",
       "1   c0/img_104.jpg           0\n",
       "2   c0/img_139.jpg           0\n",
       "3   c0/img_208.jpg           0\n",
       "4   c0/img_231.jpg           0\n",
       "5   c0/img_262.jpg           0\n",
       "6   c0/img_292.jpg           0\n",
       "7    c0/img_34.jpg           0\n",
       "8   c0/img_981.jpg           0\n",
       "9  c1/img_1045.jpg           3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_class = val_preds.argmax(axis=1)\n",
    "val_preds_df = pd.DataFrame({'image':val_generator.filenames, 'prediction':val_preds_class})\n",
    "val_preds_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uqMkuOLbi-A0"
   },
   "outputs": [],
   "source": [
    "#Extracting the class number from above image column\n",
    "y_validation = []\n",
    "for i in val_preds_df.index.values:\n",
    "    y_validation.append(int(val_preds_df.image.values[i].split('/')[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mtp8lz0Ei-u-",
    "outputId": "6cf7d491-1103-4eba-ec68-b7bd104ef9cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_validation, val_preds_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlEWAlsvjBdh"
   },
   "outputs": [],
   "source": [
    "# This seems to be ok , But however on training data model is overfitted, so needs add regularization term\n",
    "# this can be done by dropout or batch normaliztion"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
